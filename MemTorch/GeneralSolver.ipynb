{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make boxes window width. \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.functional import vjp\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Block, self).__init__()\n",
    "    def forward(self, x, t, net_params):\n",
    "        size = x.size()\n",
    "        x = F.relu(F.conv2d(x, net_params[0:9*size[1]*size[1]].view(size[1],size[1],3,3), padding=1))\n",
    "        x = F.relu(F.conv2d(x, net_params[9*size[1]*size[1]:18*size[1]*size[1]].view(size[1],size[1],3,3), padding=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "RK4 = ((  0,),\n",
    "       (1/2, 1/2,),\n",
    "       (1/2,   0,  1/2,),\n",
    "       (  1,   0,    0,   1,),\n",
    "       (1/6, 1/3, 1/3, 1/6,))\n",
    "\n",
    "EF = ((0,),\n",
    "      (1,))\n",
    "\n",
    "\"\"\"\n",
    "General Runge-Kutta Solver.\n",
    "https://en.wikipedia.org/wiki/Rungeâ€“Kutta_methods\n",
    "\n",
    "b_tableau, nested tuple, contains weights of integration. \n",
    "f, function, is the function to iterate. Should only be a function of x, t. \n",
    "x0, FloatTensor, is the intial condition.\n",
    "t0, FloatTensor, is the start time of integration.\n",
    "t1, FloatTensor, is the end time of integration.\n",
    "N, int, is the desired number of timesteps. \n",
    "\"\"\"\n",
    "\n",
    "def explicit_RK(b_tableau, f, x0, t0, t1, N):        \n",
    "    h = (t1 - t0) / float(N) # calculate step size\n",
    "    x = x0 # initialize saved dynamics\n",
    "    mesh = (t0 + h * i for i in range(N)) # generator of time values\n",
    "    for time in mesh:\n",
    "        \n",
    "        k = [f(x, time + h*b_tableau[0][0])] # Covers the first row of the Butcher tableau. \n",
    "        for i, row in enumerate(b_tableau[1:-1]): # Covers the middle rows of the Butcher tableau.\n",
    "            k.append(f(x + sum(w * k[idx] * h for idx, w in enumerate(row[1:])), time + row[0] * h)) # calculate k's. \n",
    "        x = x + sum(w * k_i * h for k_i, w in zip(k, b_tableau[-1])) # calculate timestep \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience tuple -> tensor function\n",
    "def flatten(*args):\n",
    "    return(torch.cat(tuple(torch.flatten(arg) for arg in args), dim=0).view(1,-1))\n",
    "\n",
    "# Convenience tensor -> tuple function\n",
    "def unflatten(x, n_e, sizes):\n",
    "    return (x[0, 0:n_e[0]].view(sizes[0]),\n",
    "            x[0, n_e[0]:n_e[0] + n_e[1]].view(sizes[1]),\n",
    "            x[0, (n_e[0] + n_e[1]):(n_e[0] + n_e[1] + n_e[2])].view(sizes[2]),\n",
    "            x[0, (n_e[0] + n_e[1] + n_e[2]):].view(sizes[3]),\n",
    "            )\n",
    "\n",
    "class Integrate(torch.autograd.Function):\n",
    "    def __deepcopy__(self, memo):\n",
    "        return Integrate(copy.deepcopy(memo))\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, Integrator, f, x0, t0, t1, N, net_params):\n",
    "                \n",
    "        solution = Integrator(RK4, lambda x, t: f(x, t, net_params), x0, t0, t1, N)\n",
    "            \n",
    "        # Save for jacobian calculations in backward()\n",
    "        ctx.save_for_backward(x0,t0,t1,net_params)\n",
    "        ctx.solution = solution\n",
    "        ctx.Integrator = Integrator\n",
    "        ctx.N = N\n",
    "        ctx.f = f\n",
    "        \n",
    "        return solution\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dz1):\n",
    "        # Get all saved context\n",
    "        z0, t0, t1, net_params = ctx.saved_tensors\n",
    "        z1 = ctx.solution\n",
    "        N = ctx.N\n",
    "        f = ctx.f\n",
    "        \n",
    "        # Convenience sizes\n",
    "        batch_size = z0.size()[0]\n",
    "        img_len = int(z0.numel() / batch_size)\n",
    "\n",
    "        # Compute derivative w.r.t. to end time of integration\n",
    "        dL_dt1 = dL_dz1.view(batch_size,1,-1).bmm(f(z1, t1, net_params).view(batch_size,-1,1))  # Derivative of loss w.r.t t1\n",
    "        \n",
    "        #print(\"dL_dt1\", dL_dt1)\n",
    "        \n",
    "        # Initial Condition\n",
    "        num_elements = (z1.numel(), dL_dz1.numel(), batch_size * net_params.numel(), dL_dt1.numel())\n",
    "        sizes = (z1.size(), dL_dz1.size(), (batch_size, net_params.numel()), dL_dt1.size())\n",
    "        s0 = flatten(z1, dL_dz1, torch.zeros((batch_size, net_params.numel()), dtype=torch.float32), -dL_dt1) # initial augmented state\n",
    "        \n",
    "        # augmented dynamics function\n",
    "        def aug_dynamics(s, t, theta):\n",
    "            s = unflatten(s, num_elements, sizes)\n",
    "\n",
    "            with torch.enable_grad(): \n",
    "                gradients = [vjp(f, \n",
    "                                 (s[0][i].unsqueeze(0), t, theta), \n",
    "                                  v=-s[1][i].unsqueeze(0),\n",
    "                                 )[1] for i in range(batch_size)]\n",
    "                \n",
    "            return flatten(f(s[0],t,theta),\n",
    "                    torch.cat([gradient[0] for gradient in gradients], dim=0), \n",
    "                    torch.cat([gradient[2].unsqueeze(0) for gradient in gradients], dim=0), \n",
    "                    torch.cat([gradient[1].reshape(1,1) for gradient in gradients], dim=0),\n",
    "                   )#.unsqueeze(2)\n",
    "           \n",
    "\n",
    "        # Integrate backwards\n",
    "        with torch.enable_grad():\n",
    "            s = ctx.Integrator(RK4, lambda x, t: aug_dynamics(x, t, net_params), s0, t1, t0, N)\n",
    "        \n",
    "        # Extract derivatives\n",
    "        _, dL_dz0, dL_dtheta, dL_dt0 = unflatten(s, num_elements, sizes)\n",
    "        \n",
    "        # must return something for every input to forward, None for non-tensors\n",
    "        return None, None, dL_dz0, dL_dt0, dL_dt1, None, dL_dtheta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODENet(nn.Module):\n",
    "    def __init__(self, solver, f, solver_params):\n",
    "        super(ODENet, self).__init__()\n",
    "        \n",
    "        self.f = f()\n",
    "        \n",
    "        # Controls amount of parameters\n",
    "        self.body_channels = 32\n",
    "        \n",
    "        # Head, used to mix stuff around and improve accuracy\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, self.body_channels,5,padding=2)\n",
    "        \n",
    "        \n",
    "        # Body\n",
    "        self.int_f = solver\n",
    "        self.Integrate = Integrate()\n",
    "        self.solver_params = solver_params\n",
    "        self.N = solver_params[\"N\"]\n",
    "        self.h = (solver_params[\"t1\"] - solver_params[\"t0\"]) / solver_params[\"N\"]\n",
    "        self.t0 = torch.tensor(float(solver_params[\"t0\"]), requires_grad=True)\n",
    "        self.t1 = torch.tensor(float(solver_params[\"t1\"]), requires_grad=True)\n",
    "        self.net_params = torch.nn.parameter.Parameter(torch.Tensor(self.body_channels*self.body_channels*9*2).normal_(mean=0, std=0.1,generator=None), requires_grad=True)\n",
    "\n",
    "        # Tails\n",
    "        self.avg_pool = torch.nn.MaxPool2d(2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(int(img_size*img_size* self.body_channels / 4), 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2(F.relu(self.conv1(x))) #initial dimensionality expansion\n",
    "        x = self.Integrate.apply(self.int_f, self.f, x, self.t0, self.t1, self.N, self.net_params) # Vanilla RK4\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(-1, int(img_size * img_size * self.body_channels / 4))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, test_loader, hyperparameters):\n",
    "    \n",
    "    lr = hyperparameters[\"lr\"]\n",
    "    n_epochs = hyperparameters[\"n_epochs\"]\n",
    "    momentum = hyperparameters[\"momentum\"]\n",
    "    weight_decay = hyperparameters[\"weight_decay\"]\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    \n",
    "    losses = []\n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        # Train\n",
    "        net.train()\n",
    "        train_losses = []\n",
    "        for j, (data, label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = net(torch.cat((data, torch.zeros(data.size()), torch.zeros(data.size())), dim=1)) #augmented nodes\n",
    "            loss = F.nll_loss(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "                    \n",
    "        \"\"\" Check ur gradients if the accuracy sucks\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data, param.grad)\n",
    "        \"\"\"\n",
    "        \n",
    "        num_correct, test_losses = test(net, test_loader)\n",
    "        losses.append([train_losses, test_losses])\n",
    "        \n",
    "        # Report\n",
    "        print(\n",
    "          \"Avg Train Loss\", sum(train_losses)/len(train_losses), \"\\n\"\n",
    "          \"Avg Test Loss\", sum(test_losses)/len(test_losses), \"\\n\"\n",
    "          \"Test Accuracy\", (num_correct / float(len(test_loader.dataset)) * 100).item(), \"%\"\n",
    "         )\n",
    "        print(\"----------------------------------------\")\n",
    "        \n",
    "    return losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader):\n",
    "    # Test\n",
    "    net.eval()\n",
    "    test_losses = []\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for j, (data, label) in enumerate(test_loader):\n",
    "            output = net(torch.cat((data, torch.zeros(data.size()), torch.zeros(data.size())), dim=1))\n",
    "            \n",
    "            print(output == output)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            test_losses.append(loss.item())\n",
    "            num_correct += label.eq(torch.max(output, 1, keepdim=False, out=None).indices).sum()\n",
    "\n",
    "    \n",
    "    return num_correct, test_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "img_size = 28\n",
    "img_len = 784\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/Users/louis/Desktop/neuralODE/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/Users/louis/Desktop/neuralODE/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"lr\":  0.01,\n",
    "    \"n_epochs\": 1,\n",
    "    \"momentum\": 0.5,\n",
    "    \"weight_decay\": 0.0,\n",
    "}\n",
    "\n",
    "solver_params = {\n",
    "    \"t0\": 0,\n",
    "    \"t1\": 1,\n",
    "    \"N\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-6279504b4d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTestNetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mODENet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplicit_RK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-5dbc7cdd4236>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, test_loader, hyperparameters)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#augmented nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TestNetwork = ODENet(explicit_RK, Block, solver_params).to(device)\n",
    "losses = train(TestNetwork, train_loader, test_loader, hyperparameters)\n",
    "torch.save(TestNetwork.state_dict(), \"test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
