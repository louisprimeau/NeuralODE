{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make boxes window width. \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import datetime\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Block, self).__init__()\n",
    "    def forward(self, x, t, net_params):\n",
    "        x = F.relu(F.conv2d(x, net_params[0:9].view(1,1,3,3), padding=1))\n",
    "        x = F.relu(F.conv2d(x, net_params[9:18].view(1,1,3,3), padding=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RK4(f, x0, t0, t1, N,  net_params):\n",
    "    h = (t1 - t0) / float(N) # calculate step size\n",
    "    solution = [x0] # initialize saved dynamics\n",
    "    t = t0\n",
    "    for i in range(N):\n",
    "        k1 = f(solution[i], t, net_params)\n",
    "        k2 = f(solution[i] + h * k1 / 2.0, t + h/2.0, net_params)\n",
    "        k3 = f(solution[i] + h * k2 / 2.0, t + h/2.0, net_params)\n",
    "        k4 = f(solution[i] + h * k3, t + h, net_params)\n",
    "        solution.append(solution[i] + h/6.0 * (k1 + k2 + k3 + k4))\n",
    "        t = t + h  \n",
    "    \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumb but will be replaced when ragged_tensor is a native pytorch feature\n",
    "def tuple_add(*tuples):\n",
    "    return tuple(sum(i) for i in zip(*tuples))\n",
    "def tw(a, weight):\n",
    "    return tuple(i * weight for i in a)\n",
    "\n",
    "def RK4_backward(f, x0, t0, t1, N,  net_params):\n",
    "    h = (t1 - t0) / float(N) # calculate step size\n",
    "    solution = [x0] # initialize saved dynamics\n",
    "    t = t0\n",
    "    for i in range(N):\n",
    "        k1 = f(solution[i], t, net_params)        \n",
    "        k2 = f(tuple_add(solution[i], tuple(h/2.0 * j for j in k1)), t + h/2.0, net_params)\n",
    "        k3 = f(tuple_add(solution[i], tuple(h/2.0 * j for j in k2)), t + h/2.0, net_params)\n",
    "        k4 = f(tuple_add(solution[i], tuple(h * j for j in k2)), t + h, net_params)\n",
    "        solution.append(tuple_add(solution[i], tw(k1,h/6.0), tw(k2,h/6.0), tw(k3,h/6.0), tw(k4,h/6.0)))\n",
    "        t = t + h  \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrate(torch.autograd.Function):\n",
    "    def __deepcopy__(self, memo):\n",
    "        return Integrate(copy.deepcopy(memo))\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, Integrator, Integrator_backwards, f, x0, t0, t1, N, net_params):\n",
    "        \n",
    "        # Forward, Runge-Kutta 4th Order. \n",
    "        \n",
    "        # Forward integration\n",
    "        solution = Integrator(f, x0, t0, t1, N, net_params)\n",
    "            \n",
    "        # Save for jacobian calculations in backward()\n",
    "        ctx.save_for_backward(x0,t0,t1)\n",
    "        ctx.net_params = net_params\n",
    "        ctx.solution = solution\n",
    "        ctx.Integrator_backwards = Integrator_backwards\n",
    "        ctx.N = N\n",
    "        ctx.f = f\n",
    "        \n",
    "        return solution[-1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dz1):\n",
    "        # Get all saved context\n",
    "        z0, t0, t1 = ctx.saved_tensors\n",
    "        net_params = ctx.net_params\n",
    "        dynamics = ctx.solution\n",
    "        z1 = dynamics[-1]\n",
    "        N = ctx.N\n",
    "        f = ctx.f\n",
    "        \n",
    "        # Convenience sizes\n",
    "        batch_size = z0.size()[0]\n",
    "        img_size = z0.size()[3]\n",
    "        img_len = img_size ** 2\n",
    "\n",
    "        # Compute derivative w.r.t. to end time of integration\n",
    "        dL_dt1 = dL_dz1.view(batch_size,1,-1).bmm(f(z1, t1, net_params).view(batch_size,-1,1))  # Derivative of loss w.r.t t1\n",
    "        \n",
    "        # Initial Condition\n",
    "        s0 = (z1, dL_dz1, torch.zeros((batch_size, net_params.numel()), dtype=torch.float32).to(torch.device(\"cuda:0\")), -dL_dt1) # initial augmented state\n",
    "        \n",
    "        # augmented dynamics function\n",
    "        # what I really want is a Tensorflow Ragged Tensor, and pytorch's implementation really isn't there yet\n",
    "        def aug_dynamics(s, t, theta):\n",
    "           \n",
    "            with torch.enable_grad():\n",
    "                gradients = [torch.autograd.functional.vjp(f, \n",
    "                                                           (s[0][i,:,:].unsqueeze(0), t, theta), \n",
    "                                                           v=-s[1][i,:,:].unsqueeze(0)\n",
    "                                                          )[1] for i in range(batch_size)]\n",
    "            \n",
    "            return (f(s[0],t,theta),\n",
    "                    torch.cat([gradient[0] for gradient in gradients], dim=0), \n",
    "                    torch.cat([gradient[2].reshape(1,18) for gradient in gradients], dim=0), \n",
    "                    torch.cat([gradient[1].reshape(1,1) for gradient in gradients], dim=0).to(torch.device(\"cuda:0\")),\n",
    "                   )\n",
    "        \n",
    "        # Integrate backwards\n",
    "        \n",
    "        with torch.no_grad(): back_dynamics = ctx.Integrator_backwards(aug_dynamics, s0, t1, t0, N, net_params)\n",
    "        # Extract derivatives\n",
    "        _, dL_dz0, dL_dtheta, dL_dt0 = back_dynamics[-1]\n",
    "        \n",
    "        # must return something for every input to forward, None for non-tensors\n",
    "        return None, None, None, dL_dz0, dL_dt0, dL_dt1, None, dL_dtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODENet(nn.Module):\n",
    "    def __init__(self, solver, solver_b, f, solver_params):\n",
    "        super(ODENet, self).__init__()\n",
    "        \n",
    "        self.f = f()\n",
    "        \n",
    "        self.int_f = solver\n",
    "        self.int_b = solver_b\n",
    "        self.Integrate = Integrate()\n",
    "        \n",
    "        self.solver_params = solver_params\n",
    "        self.N = solver_params[\"N\"]\n",
    "        self.h = (solver_params[\"t1\"] - solver_params[\"t0\"]) / solver_params[\"N\"]\n",
    "        self.t0 = torch.tensor(float(solver_params[\"t0\"]), requires_grad=True)\n",
    "        self.t1 = torch.tensor(float(solver_params[\"t1\"]), requires_grad=True)\n",
    "        self.net_params = torch.nn.parameter.Parameter(torch.Tensor(18).normal_(mean=0, std=0.1,generator=None), requires_grad=True)\n",
    "\n",
    "        self.avg_pool = torch.nn.MaxPool2d(2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(196, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Integrate.apply(self.int_f, self.int_b, self.f, x, self.t0, self.t1, self.N, self.net_params) # Vanilla RK4\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(-1, 196) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, test_loader, hyperparameters):\n",
    "    \n",
    "    lr = hyperparameters[\"lr\"]\n",
    "    n_epochs = hyperparameters[\"n_epochs\"]\n",
    "    momentum = hyperparameters[\"momentum\"]\n",
    "    \n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    start_TIME = time.time()\n",
    "    losses = []\n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Train\n",
    "        net.train()\n",
    "        train_losses = []\n",
    "        for j, (data, label) in enumerate(train_loader):\n",
    "            data = data.to(torch.device(\"cuda:0\"))\n",
    "            label = label.to(torch.device(\"cuda:0\"))\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        \"\"\" Check ur gradients if the accuracy sucks\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data, param.grad)\n",
    "        \"\"\"\n",
    "        \n",
    "        num_correct, test_losses = test(net, test_loader)\n",
    "        losses.append([train_losses, test_losses])\n",
    "        \n",
    "        # Report\n",
    "        print(\n",
    "          \"EPOCH\", i, \n",
    "          \"time\", print(datetime.datetime.now()), \"\\n\"\n",
    "          \"Avg Train Loss\", sum(train_losses)/len(train_losses), \"\\n\"\n",
    "          \"Avg Test Loss\", sum(test_losses)/len(test_losses), \"\\n\"\n",
    "          \"Test Accuracy\", (num_correct / float(len(test_loader.dataset)) * 100).item(), \"%\"\n",
    "         )\n",
    "        print(\"----------------------------------------\")\n",
    "        \n",
    "        torch.save(net.state_dict(), \"Test1/test_e\" + str(i) + \".pth\")\n",
    "        \n",
    "    return losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader):\n",
    "    # Test\n",
    "    net.eval()\n",
    "    test_losses = []\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for j, (data, label) in enumerate(test_loader):\n",
    "            data = data.to(torch.device(\"cuda:0\"))\n",
    "            label = label.to(torch.device(\"cuda:0\"))\n",
    "            output = net(data)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            test_losses.append(loss.item())\n",
    "            num_correct += label.eq(torch.max(output, 1, keepdim=False, out=None).indices).sum()\n",
    "\n",
    "    \n",
    "    return num_correct, test_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "img_size = 28\n",
    "img_len = 784\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"lr\":  0.01,\n",
    "    \"n_epochs\": 10,\n",
    "    \"momentum\": 0.5,\n",
    "}\n",
    "\n",
    "solver_params = {\n",
    "    \"t0\": 0,\n",
    "    \"t1\": 3,\n",
    "    \"N\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TestNetwork = ODENet(RK4, RK4_backward, Block, solver_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behaves weirdly. The first time you run it, it will throw an error saying that it expected a cpu tensor but got a gpu tensor. Just run everything except the imports again, and it will work. I don't know why it does this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 01:05:44.864906\n",
      "EPOCH 0 time None \n",
      "Avg Train Loss 0.44757418585087316 \n",
      "Avg Test Loss 0.19449862092733383 \n",
      "Test Accuracy 93.86000061035156 %\n",
      "----------------------------------------\n",
      "2020-06-01 01:14:35.999520\n",
      "EPOCH 1 time None \n",
      "Avg Train Loss 0.18004053369609277 \n",
      "Avg Test Loss 0.15600185543298722 \n",
      "Test Accuracy 95.1199951171875 %\n",
      "----------------------------------------\n",
      "2020-06-01 01:23:25.932958\n",
      "EPOCH 2 time None \n",
      "Avg Train Loss 0.14352391686425534 \n",
      "Avg Test Loss 0.12495857700705529 \n",
      "Test Accuracy 96.1500015258789 %\n",
      "----------------------------------------\n",
      "2020-06-01 01:32:10.327703\n",
      "EPOCH 3 time None \n",
      "Avg Train Loss 0.12284196385823841 \n",
      "Avg Test Loss 0.13107190355658532 \n",
      "Test Accuracy 95.86000061035156 %\n",
      "----------------------------------------\n",
      "2020-06-01 01:40:55.840195\n",
      "EPOCH 4 time None \n",
      "Avg Train Loss 0.11117728205441411 \n",
      "Avg Test Loss 0.10996657982468605 \n",
      "Test Accuracy 96.5999984741211 %\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TestNetwork = TestNetwork.to(torch.device(\"cuda:0\"))\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "losses = train(TestNetwork, train_loader, test_loader, hyperparameters)\n",
    "\n",
    "\n",
    "for name, param in TestNetwork.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data, param.data.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
